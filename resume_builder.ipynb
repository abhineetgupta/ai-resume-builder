{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2404c675-ed88-48ea-89f4-5f8b66945068",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e588ea9b-a56d-448b-8a76-6feef951e56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from IPython.display import display, Markdown\n",
    "from pathvalidate import sanitize_filename\n",
    "\n",
    "import utils\n",
    "\n",
    "from prompts import Job_Post, Resume_Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e52eea83-6cae-48c1-a59d-9b240e96ff94",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inputs\n",
    "my_files_dir = \"my_applications\"  # location for all job and resume files\n",
    "job_file = \"job.txt\"  # filename with job post text. The entire job post can be pasted in this file, as is.\n",
    "raw_resume_file = \"resume_raw.yaml\"  # filename for raw resume yaml. See example in repo for instructions.\n",
    "\n",
    "# Model for matching resume to job post (except extraction chains)\n",
    "# gpt-4 is not publicly available yet and can be 20-30 times costlier than the default model gpt-3.5-turbo.\n",
    "# Simple extraction chains are hardcoded to use the cheaper gpt-3.5 model.\n",
    "openai_model_name = \"gpt-4\"\n",
    "# openai_model_name = \"gpt-3.5-turbo\"\n",
    "\n",
    "# temperature lower than 1 is preferred. temperature=0 returns deterministic output\n",
    "temperature = 0.5\n",
    "\n",
    "llm_kwargs = dict(\n",
    "    model_name=openai_model_name,\n",
    "    model_kwargs=dict(top_p=0.6, frequency_penalty=0.1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1a0a1ca-3621-4dc7-a34d-c6f9eafd1b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a world class algorithm for extracting information in structured formats.\n",
      "Human: Use the given format to extract information from the following input:\n",
      "Human: Varo represents a new generation of fintech built on technology and innovation to empower consumers. We serve millions of Americans with our mobile app to make digital banking easy, convenient, and personalized.\n",
      "\n",
      "We believe the future of lending in fintech lies with Machine Learning. Be one of the first scientists in the world to innovate models that dynamically set credit limits, decide loan eligibility, and predict customer borrowing behavior. You’ll lead Machine Learning in lending at Varo, working on predictive insights and underwriting models that enable broader, more inclusive, and affordable access to credit for customers.\n",
      "\n",
      "The Lead Machine Learning Scientist in Lending will be responsible for developing the machine learning models that will underlie Varo’s lending products. You will own the development and training of these models, as well as contribute to the design of architecture that serves the models.\n",
      "\n",
      "About The Data Science Team\n",
      "\n",
      "Varo’s Data Science Team develops Machine Learning models that make it easier for the right people to get access to funds, help protect customers from fraudsters, and transform the in-app experience with real-time recommendations. Unlike some organizations where data takes a support role, here at Varo data science is front and center. Since we are in hyper-growth mode, you will get to work on the most impactful data science problems from day one. We rely on advanced techniques in machine learning, cloud platforms, and data technology. We’re a team of PhDs and ex-academics with a collegial work atmosphere. If you are interested in working with an impressive team of Data pros who collaborate and challenge each other and want to solve interesting problems to propel the company’s growth, apply now!\n",
      "\n",
      "What You'll Be Doing\n",
      "\n",
      "    Lead efforts within the organization to drive the design, development, optimization, and productionization of ML-based lending and underwriting models\n",
      "    Help acquire both traditional and alternative data sets and turn them into useful predictive features\n",
      "    Enable broader, more inclusive, and affordable access to credit for individuals by growing Varo’s lending products\n",
      "    Work with stakeholders in the lending the organization to identify opportunities for driving business decisions or improving our product suite with ML\n",
      "    Collaborate cross-functionally with the engineering team to deploy models and monitor outcomes\n",
      "    Guide and mentor junior machine learning scientists and engineers\n",
      "\n",
      "You’ll Bring The Following Required Skills And Experiences\n",
      "\n",
      "    5+ years expertise in developing ML industry applications for lending or risk applications\n",
      "    Demonstrated experience and/or interest in building credit risk models and underwriting models\n",
      "    Ph.D. or equivalent in Economics, Computer Science, Statistics, or related field\n",
      "    Strong bias for action and team player\n",
      "    Ability to thrive in a fast-paced environment\n",
      "    Preferred: Familiarity with Sagemaker, Spark, TensorFlow, Keras, and PyTorch\n",
      "\n",
      "We recognize not everyone will have all of these requirements. If you meet most of the criteria above and you’re excited about the opportunity and willing to learn, we’d love to hear from you!\n",
      "\n",
      "About Varo\n",
      "\n",
      "Varo launched in 2017 with the vision to bring the best of fintech into the regulated banking system. We’re a new kind of bank – all-digital, mission-driven, FDIC-insured, and designed around the modern American consumer.\n",
      "\n",
      "As the first consumer fintech to be granted a national bank charter in 2020, we make financial inclusion and opportunity for all a reality by empowering everyone with the products, insights, and support they need to get ahead. Through our core product offerings and suite of customer-first features, we aim to address a broad range of consumer needs while profitably serving underserved communities that have been historically excluded from the traditional financial system.\n",
      "\n",
      "We are growing quickly in our hub locations of San Francisco, Salt Lake City, and Charlotte along with colleagues located across the country. We have been recognized among Fast Company’s Most Innovative Companies, Forbes’ Fintech 50, and earned the No. 7 spot on Inc. 5000’s list of fastest-growing companies across the country.\n",
      "Human: Tips: Make sure to answer in the correct format.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a world class algorithm for extracting information in structured formats.\n",
      "Human: Use the given format to extract information from the following input:\n",
      "Human: Varo represents a new generation of fintech built on technology and innovation to empower consumers. We serve millions of Americans with our mobile app to make digital banking easy, convenient, and personalized.\n",
      "\n",
      "We believe the future of lending in fintech lies with Machine Learning. Be one of the first scientists in the world to innovate models that dynamically set credit limits, decide loan eligibility, and predict customer borrowing behavior. You’ll lead Machine Learning in lending at Varo, working on predictive insights and underwriting models that enable broader, more inclusive, and affordable access to credit for customers.\n",
      "\n",
      "The Lead Machine Learning Scientist in Lending will be responsible for developing the machine learning models that will underlie Varo’s lending products. You will own the development and training of these models, as well as contribute to the design of architecture that serves the models.\n",
      "\n",
      "About The Data Science Team\n",
      "\n",
      "Varo’s Data Science Team develops Machine Learning models that make it easier for the right people to get access to funds, help protect customers from fraudsters, and transform the in-app experience with real-time recommendations. Unlike some organizations where data takes a support role, here at Varo data science is front and center. Since we are in hyper-growth mode, you will get to work on the most impactful data science problems from day one. We rely on advanced techniques in machine learning, cloud platforms, and data technology. We’re a team of PhDs and ex-academics with a collegial work atmosphere. If you are interested in working with an impressive team of Data pros who collaborate and challenge each other and want to solve interesting problems to propel the company’s growth, apply now!\n",
      "\n",
      "What You'll Be Doing\n",
      "\n",
      "    Lead efforts within the organization to drive the design, development, optimization, and productionization of ML-based lending and underwriting models\n",
      "    Help acquire both traditional and alternative data sets and turn them into useful predictive features\n",
      "    Enable broader, more inclusive, and affordable access to credit for individuals by growing Varo’s lending products\n",
      "    Work with stakeholders in the lending the organization to identify opportunities for driving business decisions or improving our product suite with ML\n",
      "    Collaborate cross-functionally with the engineering team to deploy models and monitor outcomes\n",
      "    Guide and mentor junior machine learning scientists and engineers\n",
      "\n",
      "You’ll Bring The Following Required Skills And Experiences\n",
      "\n",
      "    5+ years expertise in developing ML industry applications for lending or risk applications\n",
      "    Demonstrated experience and/or interest in building credit risk models and underwriting models\n",
      "    Ph.D. or equivalent in Economics, Computer Science, Statistics, or related field\n",
      "    Strong bias for action and team player\n",
      "    Ability to thrive in a fast-paced environment\n",
      "    Preferred: Familiarity with Sagemaker, Spark, TensorFlow, Keras, and PyTorch\n",
      "\n",
      "We recognize not everyone will have all of these requirements. If you meet most of the criteria above and you’re excited about the opportunity and willing to learn, we’d love to hear from you!\n",
      "\n",
      "About Varo\n",
      "\n",
      "Varo launched in 2017 with the vision to bring the best of fintech into the regulated banking system. We’re a new kind of bank – all-digital, mission-driven, FDIC-insured, and designed around the modern American consumer.\n",
      "\n",
      "As the first consumer fintech to be granted a national bank charter in 2020, we make financial inclusion and opportunity for all a reality by empowering everyone with the products, insights, and support they need to get ahead. Through our core product offerings and suite of customer-first features, we aim to address a broad range of consumer needs while profitably serving underserved communities that have been historically excluded from the traditional financial system.\n",
      "\n",
      "We are growing quickly in our hub locations of San Francisco, Salt Lake City, and Charlotte along with colleagues located across the country. We have been recognized among Fast Company’s Most Innovative Companies, Forbes’ Fintech 50, and earned the No. 7 spot on Inc. 5000’s list of fastest-growing companies across the country.\n",
      "Human: Tips: Make sure to answer in the correct format.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "#filename: my_applications/20231202__Varo__Lead Machine Learning Scientist in Lending.job\n",
      "\n",
      "company: Varo\n",
      "job_title: Lead Machine Learning Scientist in Lending\n",
      "team: Data Science Team\n",
      "job_summary: Lead efforts within the organization to drive the design, development,\n",
      "  optimization, and productionization of ML-based lending and underwriting models.\n",
      "  Help acquire both traditional and alternative data sets and turn them into useful\n",
      "  predictive features. Enable broader, more inclusive, and affordable access to credit\n",
      "  for individuals by growing Varo’s lending products. Work with stakeholders in the\n",
      "  lending organization to identify opportunities for driving business decisions or\n",
      "  improving our product suite with ML. Collaborate cross-functionally with the engineering\n",
      "  team to deploy models and monitor outcomes. Guide and mentor junior machine learning\n",
      "  scientists and engineers.\n",
      "salary: ''\n",
      "duties:\n",
      "- Lead efforts within the organization to drive the design, development, optimization,\n",
      "  and productionization of ML-based lending and underwriting models\n",
      "- Help acquire both traditional and alternative data sets and turn them into useful\n",
      "  predictive features\n",
      "- Enable broader, more inclusive, and affordable access to credit for individuals\n",
      "  by growing Varo’s lending products\n",
      "- Work with stakeholders in the lending organization to identify opportunities for\n",
      "  driving business decisions or improving our product suite with ML\n",
      "- Collaborate cross-functionally with the engineering team to deploy models and monitor\n",
      "  outcomes\n",
      "- Guide and mentor junior machine learning scientists and engineers\n",
      "qualifications:\n",
      "- 5+ years expertise in developing ML industry applications for lending or risk applications\n",
      "- Demonstrated experience and/or interest in building credit risk models and underwriting\n",
      "  models\n",
      "- Ph.D. or equivalent in Economics, Computer Science, Statistics, or related field\n",
      "- Strong bias for action and team player\n",
      "- Ability to thrive in a fast-paced environment\n",
      "- 'Preferred: Familiarity with Sagemaker, Spark, TensorFlow, Keras, and PyTorch'\n",
      "is_fully_remote: false\n",
      "technical_skills:\n",
      "- Machine Learning\n",
      "- Credit Risk Models\n",
      "- Underwriting Models\n",
      "- Sagemaker\n",
      "- Spark\n",
      "- TensorFlow\n",
      "- Keras\n",
      "- PyTorch\n",
      "non_technical_skills:\n",
      "- Leadership\n",
      "- Collaboration\n",
      "- Mentoring\n",
      "- Problem Solving\n",
      "- Fast-paced Environment\n"
     ]
    }
   ],
   "source": [
    "# Step 1 - Read and parse job posting\n",
    "job_post = Job_Post(\n",
    "    utils.read_jobfile(os.path.join(my_files_dir, job_file)),\n",
    ")\n",
    "parsed_job = job_post.parse_job_post(verbose=False)\n",
    "\n",
    "company_name = parsed_job[\"company\"]\n",
    "job_title = parsed_job[\"job_title\"]\n",
    "today_date = datetime.today().strftime(\"%Y%m%d\")\n",
    "job_filename = os.path.join(\n",
    "    my_files_dir, sanitize_filename(f\"{today_date}__{company_name}__{job_title}\")\n",
    ")\n",
    "print(f\"#filename: {job_filename}.job\\n\")\n",
    "utils.write_yaml(parsed_job, filename=f\"{job_filename}.job\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b6c0aac-9a22-4de0-8400-8769e944e763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - read raw resume and create Resume builder object\n",
    "my_resume = Resume_Builder(\n",
    "    resume=utils.read_yaml(filename=os.path.join(my_files_dir, raw_resume_file)),\n",
    "    parsed_job=parsed_job,\n",
    "    llm_kwargs=llm_kwargs,\n",
    ")\n",
    "projects = my_resume.projects_raw\n",
    "experiences = my_resume.experiences_raw\n",
    "skills = my_resume.skills_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c242c2a6-ef33-403c-bf2e-7926cf8d43fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are an expert technical writer. Your goal is to strictly follow all the provided <Steps> and meet all the given <Criteria>.\n",
      "Human: <Instruction> Identify the relevant portions from the <Master Resume> that match the <Job Posting>, rephrase these relevant portions into highlights, and rate the relevance of each highlight to the <Job Posting> on a scale of 1-5.\n",
      "Human: <Criteria> \n",
      "- Each highlight must be based on what is mentioned in the <Master Resume>.\n",
      "- In each highlight, include how that experience in the <Master Resume> demonstrates an ability to perform duties mentioned in the <Job Posting>.\n",
      "- In each highlight, try to include action verbs, give tangible and concrete examples, and include success metrics when available.\n",
      "- Grammar, spellings, and sentence structure must be correct.\n",
      "Human: <Steps>\n",
      "- Create a <Plan> for following the <Instruction> while meeting all the <Criteria>.\n",
      "- What <Additional Steps> are needed to follow the <Plan>?\n",
      "- Follow all steps one by one and show your <Work>.\n",
      "- Verify that highlights are reflective of the <Master Resume> and not the <Job Posting>. Update if necessary.\n",
      "- Verify that all <Criteria> are met, and update if necessary.\n",
      "- Provide the answer to the <Instruction> with prefix <Final Answer>.\n",
      "Human: <Job Posting>\n",
      "The ideal candidate is able to perform the following duties:\n",
      "- Lead efforts within the organization to drive the design, development, optimization, and productionization of ML-based lending and underwriting models\n",
      "- Help acquire both traditional and alternative data sets and turn them into useful predictive features\n",
      "- Enable broader, more inclusive, and affordable access to credit for individuals by growing Varo’s lending products\n",
      "- Work with stakeholders in the lending organization to identify opportunities for driving business decisions or improving our product suite with ML\n",
      "- Collaborate cross-functionally with the engineering team to deploy models and monitor outcomes\n",
      "- Guide and mentor junior machine learning scientists and engineers\n",
      "\n",
      "The ideal candidate has the following qualifications:\n",
      "- 5+ years expertise in developing ML industry applications for lending or risk applications\n",
      "- Demonstrated experience and/or interest in building credit risk models and underwriting models\n",
      "- Ph.D. or equivalent in Economics, Computer Science, Statistics, or related field\n",
      "- Strong bias for action and team player\n",
      "- Ability to thrive in a fast-paced environment\n",
      "- Preferred: Familiarity with Sagemaker, Spark, TensorFlow, Keras, and PyTorch\n",
      "\n",
      "The ideal candidate has the following skills:\n",
      "- Machine Learning\n",
      "- Credit Risk Models\n",
      "- Underwriting Models\n",
      "- Sagemaker\n",
      "- Spark\n",
      "- TensorFlow\n",
      "- Keras\n",
      "- PyTorch\n",
      "\n",
      "- Leadership\n",
      "- Collaboration\n",
      "- Mentoring\n",
      "- Problem Solving\n",
      "- Fast-paced Environment\n",
      "Human: <Master Resume>\n",
      "- I led the work on machine learning models for fraud detection at Marqeta. Starting the project from scratch,  I built up domain expertise in card fraud/risk, deeply understood the data at Marqeta, and trained fraud detection models.\n",
      "- I exemplified great leadership and worked independently in a seamless fashion across challenging stakeholders.\n",
      "- I launched a large project to collect training data involving billions of transactions with over 300 features, and built a pipeline to compile the complete dataset to share with our vendors. I also found and fixed bugs in their open API specs.\n",
      "- I updated the training dataset pipeline to share with another vendor, worked with security and privacy team to identify and hash PII fields, and shared the data with the new vendor.\n",
      "- I created our comprehensive strategy for evaluating vendors' supervised and unsupervised fraud models, including online and offline evaluations.\n",
      "- I set up AWS Sagemaker Studio in VPC after it became non-responsive in VPC only mode. Successfully set up Glue in Sagemaker Studio that now enables ML engineers on the team to use Pyspark. I wrote a Pyspark evaluation library for evaluating fraud risk ML models.\n",
      "- I created the design doc for setting up ML infrastructure, clearly setting out requirements for exploratory analyses, feature generation, ML training and experimentation, model deployment, model monitoring, and model evaluation.\n",
      "- I experimented with using dbt in our ETL pipelines and set up best practice guidelines as dbt gets rolled out to the broader data engineering team.\n",
      "- During 2 weeks data ops rotation, I automated the process of daily Instacart email, that reduced onboarding effort required from ~2 hours to < 30 minutes, and daily effort required from ~30 minutes to ~15 minutes. It minimized possibilities of critical errors, thus saving both hndreds of hours of people time.\n",
      "- I introduced MLOps concepts, and discussed current state-of-the-art practices with the ML team to set the stage for efficient collaboration during ML model development, experimentation, and deployment phases.\n",
      "- I communicated and shared ML best practices with the leadership and executive teams to promote sustained future growth of ML.\n",
      "- I worked with the team to foster a strong community.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Chain output:\n",
      "<Plan>\n",
      "1. Review the <Master Resume> and <Job Posting> thoroughly.\n",
      "2. Identify the relevant portions from the <Master Resume> that match the <Job Posting>.\n",
      "3. Rephrase these relevant portions into highlights.\n",
      "4. Rate the relevance of each highlight to the <Job Posting> on a scale of 1-5.\n",
      "5. Ensure each highlight meets the <Criteria>.\n",
      "6. Make any necessary adjustments to ensure all <Criteria> are met.\n",
      "\n",
      "<Additional Steps>\n",
      "1. Cross-check each highlight against the <Master Resume> to ensure it accurately reflects the information provided.\n",
      "2. Cross-check each highlight against the <Job Posting> to ensure it is relevant.\n",
      "\n",
      "<Work>\n",
      "1. Identified Relevant Portions:\n",
      "   - Led machine learning models for fraud detection at Marqeta.\n",
      "   - Demonstrated leadership and worked independently across challenging stakeholders.\n",
      "   - Launched a large project to collect training data involving billions of transactions with over 300 features.\n",
      "   - Set up AWS Sagemaker Studio in VPC, enabling ML engineers on the team to use Pyspark.\n",
      "   - Created the design doc for setting up ML infrastructure.\n",
      "   - Introduced MLOps concepts and discussed current state-of-the-art practices with the ML team.\n",
      "   - Communicated and shared ML best practices with the leadership and executive teams.\n",
      "\n",
      "2. Rephrased into Highlights:\n",
      "   - Demonstrated ability to lead machine learning projects, as evidenced by successfully leading a fraud detection project at Marqeta, demonstrating both technical expertise and leadership skills (Relevance: 5/5).\n",
      "   - Proven experience in handling large datasets, as shown by launching a project involving billions of transactions with over 300 features (Relevance: 4/5).\n",
      "   - Strong familiarity with AWS Sagemaker and Pyspark, as demonstrated by setting up AWS Sagemaker Studio in VPC for use by ML engineers (Relevance: 5/5).\n",
      "   - Demonstrated ability to design and implement ML infrastructure, as shown by the creation of a comprehensive design doc (Relevance: 5/5).\n",
      "   - Experience in introducing and discussing MLOps concepts with the ML team, indicating a strong understanding of current practices in the field (Relevance: 4/5).\n",
      "   - Proven ability to communicate and share ML best practices with leadership and executive teams, demonstrating strong communication and leadership skills (Relevance: 4/5).\n",
      "\n",
      "3. All highlights meet the <Criteria>.\n",
      "\n",
      "<Final Answer>\n",
      "- Demonstrated ability to lead machine learning projects, as evidenced by successfully leading a fraud detection project at Marqeta, demonstrating both technical expertise and leadership skills (Relevance: 5/5).\n",
      "- Proven experience in handling large datasets, as shown by launching a project involving billions of transactions with over 300 features (Relevance: 4/5).\n",
      "- Strong familiarity with AWS Sagemaker and Pyspark, as demonstrated by setting up AWS Sagemaker Studio in VPC for use by ML engineers (Relevance: 5/5).\n",
      "- Demonstrated ability to design and implement ML infrastructure, as shown by the creation of a comprehensive design doc (Relevance: 5/5).\n",
      "- Experience in introducing and discussing MLOps concepts with the ML team, indicating a strong understanding of current practices in the field (Relevance: 4/5).\n",
      "- Proven ability to communicate and share ML best practices with leadership and executive teams, demonstrating strong communication and leadership skills (Relevance: 4/5).\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are an expert technical writer. Your goal is to strictly follow all the provided <Steps> and meet all the given <Criteria>.\n",
      "Human: <Instruction> Identify the relevant portions from the <Master Resume> that match the <Job Posting>, rephrase these relevant portions into highlights, and rate the relevance of each highlight to the <Job Posting> on a scale of 1-5.\n",
      "Human: <Criteria> \n",
      "- Each highlight must be based on what is mentioned in the <Master Resume>.\n",
      "- In each highlight, include how that experience in the <Master Resume> demonstrates an ability to perform duties mentioned in the <Job Posting>.\n",
      "- In each highlight, try to include action verbs, give tangible and concrete examples, and include success metrics when available.\n",
      "- Grammar, spellings, and sentence structure must be correct.\n",
      "Human: <Steps>\n",
      "- Create a <Plan> for following the <Instruction> while meeting all the <Criteria>.\n",
      "- What <Additional Steps> are needed to follow the <Plan>?\n",
      "- Follow all steps one by one and show your <Work>.\n",
      "- Verify that highlights are reflective of the <Master Resume> and not the <Job Posting>. Update if necessary.\n",
      "- Verify that all <Criteria> are met, and update if necessary.\n",
      "- Provide the answer to the <Instruction> with prefix <Final Answer>.\n",
      "Human: <Job Posting>\n",
      "The ideal candidate is able to perform the following duties:\n",
      "- Lead efforts within the organization to drive the design, development, optimization, and productionization of ML-based lending and underwriting models\n",
      "- Help acquire both traditional and alternative data sets and turn them into useful predictive features\n",
      "- Enable broader, more inclusive, and affordable access to credit for individuals by growing Varo’s lending products\n",
      "- Work with stakeholders in the lending organization to identify opportunities for driving business decisions or improving our product suite with ML\n",
      "- Collaborate cross-functionally with the engineering team to deploy models and monitor outcomes\n",
      "- Guide and mentor junior machine learning scientists and engineers\n",
      "\n",
      "The ideal candidate has the following qualifications:\n",
      "- 5+ years expertise in developing ML industry applications for lending or risk applications\n",
      "- Demonstrated experience and/or interest in building credit risk models and underwriting models\n",
      "- Ph.D. or equivalent in Economics, Computer Science, Statistics, or related field\n",
      "- Strong bias for action and team player\n",
      "- Ability to thrive in a fast-paced environment\n",
      "- Preferred: Familiarity with Sagemaker, Spark, TensorFlow, Keras, and PyTorch\n",
      "\n",
      "The ideal candidate has the following skills:\n",
      "- Machine Learning\n",
      "- Credit Risk Models\n",
      "- Underwriting Models\n",
      "- Sagemaker\n",
      "- Spark\n",
      "- TensorFlow\n",
      "- Keras\n",
      "- PyTorch\n",
      "\n",
      "- Leadership\n",
      "- Collaboration\n",
      "- Mentoring\n",
      "- Problem Solving\n",
      "- Fast-paced Environment\n",
      "Human: <Master Resume>\n",
      "- I led the research team to develop production-ready statistical epidemiological models for a COVID-19 Calculator. We published a peer-reviewed journal paper about the project.\n",
      "- I performed data ingestion, code optimization and parallelizing, integration with engineering, user feedback incorporation, and model validation.\n",
      "- I established and led the model validation process for physics + machine learning based natural hazard risk forecasting models, aimed at building trust for existing and potential clients.\n",
      "- I have a successful patent for developing the probabilistic machine learning model to estimate impacts to buildings after an earthquake,\n",
      "- I performed synthetic data generation, feature engineering, model selection, development of custom domain-specific evaluation metrics, and spatial and temporal validation.\n",
      "- I created the framework for quantifying resilience metrics for communities and businesses to assess their direct and indirect risk from disasters and climate change.\n",
      "- I mentored data scientists for developing a multi-stage machine learning and computer vision models to identify soft-story buildings using Google StreetView images. We delivered project findings to the city and presented the project at a sesimic conference.\n",
      "- I managed collaborations with universities and research institutions, including proposal writing and executing MOUs, to build key technologies in network analysis, disaster impacts, and scenario assessments.\n",
      "- I served as the technical expert for business development with frequent international travel, and helped close over a USD 90 million deal.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Chain output:\n",
      "<Plan>\n",
      "1. Identify the relevant portions from the <Master Resume> that match the <Job Posting>.\n",
      "2. Rephrase these relevant portions into highlights.\n",
      "3. Rate the relevance of each highlight to the <Job Posting> on a scale of 1-5.\n",
      "4. Ensure each highlight demonstrates an ability to perform duties mentioned in the <Job Posting>.\n",
      "5. Include action verbs, tangible and concrete examples, and success metrics when available in each highlight.\n",
      "6. Check grammar, spellings, and sentence structure.\n",
      "\n",
      "<Additional Steps>\n",
      "1. Review the <Master Resume> and <Job Posting> thoroughly.\n",
      "2. Make a list of all the duties, qualifications, and skills mentioned in the <Job Posting>.\n",
      "3. Find matching experiences, qualifications, and skills in the <Master Resume>.\n",
      "4. Follow the steps in the <Plan>.\n",
      "\n",
      "<Work>\n",
      "1. Highlight: Led the research team to develop production-ready statistical epidemiological models for a COVID-19 Calculator. (Relevance: 4)\n",
      "2. Highlight: Established and led the model validation process for physics + machine learning based natural hazard risk forecasting models. (Relevance: 5)\n",
      "3. Highlight: Mentored data scientists for developing a multi-stage machine learning and computer vision models. (Relevance: 5)\n",
      "4. Highlight: Managed collaborations with universities and research institutions, including proposal writing and executing MOUs. (Relevance: 4)\n",
      "5. Highlight: Served as the technical expert for business development with frequent international travel, and helped close over a USD 90 million deal. (Relevance: 3)\n",
      "\n",
      "<Final Answer>\n",
      "1. Led a team to develop production-ready statistical models, demonstrating leadership and machine learning expertise relevant to driving the design, development, optimization, and productionization of ML-based lending and underwriting models (Relevance: 4).\n",
      "2. Established a model validation process for machine learning based risk forecasting models, showcasing experience in turning data sets into useful predictive features and building credit risk models (Relevance: 5).\n",
      "3. Mentored data scientists in developing machine learning models, reflecting the ability to guide and mentor junior machine learning scientists and engineers (Relevance: 5).\n",
      "4. Managed collaborations with research institutions, demonstrating the capacity to collaborate cross-functionally with different teams (Relevance: 4).\n",
      "5. Acted as a technical expert for business development and closed a USD 90 million deal, indicating a strong bias for action and ability to thrive in a fast-paced environment (Relevance: 3).\n",
      "experiences:\n",
      "- company: Marqeta, Oakland CA\n",
      "  titles:\n",
      "  - name: Staff Machine Learning Researcher\n",
      "    startdate: 2022\n",
      "    enddate: current\n",
      "  highlights:\n",
      "  - Demonstrated ability to lead machine learning projects, as evidenced by successfully\n",
      "    leading a fraud detection project at Marqeta, demonstrating both technical expertise\n",
      "    and leadership skills\n",
      "  - Strong familiarity with AWS Sagemaker and Pyspark, as demonstrated by setting\n",
      "    up AWS Sagemaker Studio in VPC for use by ML engineers\n",
      "  - Demonstrated ability to design and implement ML infrastructure, as shown by the\n",
      "    creation of a comprehensive design doc\n",
      "  - Proven experience in handling large datasets, as shown by launching a project\n",
      "    involving billions of transactions with over 300 features\n",
      "  - Experience in introducing and discussing MLOps concepts with the ML team, indicating\n",
      "    a strong understanding of current practices in the field\n",
      "  - Proven ability to communicate and share ML best practices with leadership and\n",
      "    executive teams, demonstrating strong communication and leadership skills\n",
      "- company: One Concern Inc., Menlo Park CA\n",
      "  titles:\n",
      "  - name: Director of Research\n",
      "    startdate: 2020\n",
      "    enddate: 2022\n",
      "  - name: Lead Machine Learning Engineer in Resilience team\n",
      "    startdate: 2017\n",
      "    enddate: 2020\n",
      "  - name: Machine Learning Researcher\n",
      "    startdate: 2015\n",
      "    enddate: 2017\n",
      "  highlights:\n",
      "  - Established a model validation process for machine learning based risk forecasting\n",
      "    models, showcasing experience in turning data sets into useful predictive features\n",
      "    and building credit risk models\n",
      "  - Mentored data scientists in developing machine learning models, reflecting the\n",
      "    ability to guide and mentor junior machine learning scientists and engineers\n",
      "  - Led a team to develop production-ready statistical models, demonstrating leadership\n",
      "    and machine learning expertise relevant to driving the design, development, optimization,\n",
      "    and productionization of ML-based lending and underwriting models\n",
      "  - Managed collaborations with research institutions, demonstrating the capacity\n",
      "    to collaborate cross-functionally with different teams\n",
      "  - Acted as a technical expert for business development and closed a USD 90 million\n",
      "    deal, indicating a strong bias for action and ability to thrive in a fast-paced\n",
      "    environment\n",
      "- company: Magnusson Klemencic Associates\n",
      "  titles:\n",
      "  - name: Structural Design Engineer\n",
      "    startdate: 2011\n",
      "    enddate: 2013\n",
      "  highlights:\n",
      "  - Engineered and managed construction of iconic buildings that brought in multi-million\n",
      "    dollars revenue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3 - Rephrase unedited experiences. Try re-running cells in case of missing answers or hallucinations.\n",
    "experiences = my_resume.rewrite_unedited_experiences(verbose=True)\n",
    "utils.write_yaml(dict(experiences=experiences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78577096-41ca-4b3b-91f4-2af1fc4931bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the generated output in previous cell.\n",
    "# If any updates are needed, copy the cell output below between the triple quotes\n",
    "# Set value to \"\"\"\" \"\"\"\" if no edits are needed\n",
    "edits = \"\"\"experiences:\n",
    "- company: Marqeta, Oakland CA\n",
    "  titles:\n",
    "  - name: Staff Machine Learning Researcher\n",
    "    startdate: 2022\n",
    "    enddate: current\n",
    "  highlights:\n",
    "  - Demonstrated ability to lead machine learning projects, as evidenced by successfully\n",
    "    leading a fraud detection project at Marqeta, demonstrating both technical expertise\n",
    "    and leadership skills\n",
    "  - Strong familiarity with AWS Sagemaker and Pyspark, as demonstrated by setting\n",
    "    up AWS Sagemaker Studio in VPC and writing\n",
    "    Pyspark ML financial model evaluation library.\n",
    "  - Demonstrated ability to design and implement ML infrastructure, as shown by the\n",
    "    creation of a comprehensive design doc\n",
    "  - Proven experience in handling large datasets, as shown by launching a project\n",
    "    involving billions of transactions with over 300 features\n",
    "  - Experience in introducing and discussing MLOps concepts with the ML team, indicating\n",
    "    a strong understanding of current practices in the field\n",
    "  - Proven ability to communicate and share ML best practices with leadership and\n",
    "    executive teams, demonstrating strong communication and leadership skills\n",
    "  - Led the machine learning project for risk and fraud detection in card transactions, \n",
    "    demonstrating expertise in end-to-end ML development including data processing, feature\n",
    "    engineering, model training, and evaluation, and showcasing ability to work closely with \n",
    "    Product Managers, Engineers, and Researchers.\n",
    "  - Launched a large project to collect training data for billions of transactions\n",
    "    and over 1000 features, and built a pipeline to share data with stakeholders while\n",
    "    ensuring security and privacy compliance, showcasing the ability to work\n",
    "    in a fast-paced, dynamic environment and practical experience in data analysis,\n",
    "    statistics, and experimentation.\n",
    "  - Built a thorough evaluation methodology for vendors' supervised and unsupervised\n",
    "    fraud models. Successfully evaluated\n",
    "    vendors' fraud models and communicated the results to leadership, demonstrating strong \n",
    "    problem-solving skills and the ability\n",
    "    to foster data-driven business decisions.\n",
    "  - Successfully set up AWS Sagemaker Studio and Glue in VPC to enable ML engineers\n",
    "    to use Pyspark, highlighting experience with development of AI models on managed cloud services. Wrote \n",
    "    Pyspark ML financial model evaluation library.\n",
    "  - Introduced MLOps best practices to the ML team, promoting efficient collaboration\n",
    "    during model development, and showcasing experience in collaborating and influencing technical teams.\n",
    "  - Demonstrated leadership skills by working independently across challenging stakeholders,\n",
    "    fostering seamless collaboration and achieving successful outcomes.\n",
    "- company: One Concern Inc., Menlo Park CA\n",
    "  titles:\n",
    "  - name: Director of Research\n",
    "    startdate: 2020\n",
    "    enddate: 2022\n",
    "  - name: Lead Machine Learning Engineer in Resilience team\n",
    "    startdate: 2017\n",
    "    enddate: 2020\n",
    "  - name: Machine Learning Researcher\n",
    "    startdate: 2015\n",
    "    enddate: 2017\n",
    "  highlights:\n",
    "  - Developed and validated physics + machine learning based natural hazard models,\n",
    "    building trust for existing and potential clients, and ensuring highest safety\n",
    "    standards for ML models.\n",
    "  - Led a research team to develop statistical epidemiological models for COVID-19\n",
    "    Calculator, resulting in a peer-reviewed journal paper publication, and\n",
    "    highlighting the ability to analyze\n",
    "    large-scale time series data, suggest innovative solutions and extend progress and trends from\n",
    "    academia to real-world problems.\n",
    "  - Successfully patented a probabilistic machine learning model for estimating infrastructure\n",
    "    impacts after an earthquake, showcasing the ability to deliver high level of technical\n",
    "    quality and drive high impact projects.\n",
    "  - Mentored data scientists in developing multi-stage machine learning and computer\n",
    "    vision models that successfully identified soft-story buildings using Google StreetView\n",
    "    images, providing technical leadership and mentoring. Presented the project findings\n",
    "    at a seismic conference.\n",
    "  - Served as the technical expert for business development, with frequent international\n",
    "    travel, and played a crucial role in closing a \\$90 million deal, demonstrating\n",
    "    the ability to communicate complex technical ideas to both technical and non-technical \n",
    "    stakeholders with clarity and precision.\n",
    "  - Managed collaborations\n",
    "    with prestigious universities and research institutions, resulting in the development\n",
    "    of cutting-edge technologies in network analysis and disaster impacts.\n",
    "\"\"\"\n",
    "\n",
    "edits = edits.strip()\n",
    "if edits:\n",
    "    edits1 = utils.read_yaml(edits)\n",
    "    if \"experiences\" in edits1:\n",
    "        experiences = edits1[\"experiences\"]\n",
    "    if \"projects\" in edits1:\n",
    "        projects = edits1[\"projects\"]\n",
    "    if \"skills\" in edits1:\n",
    "        skills = edits1[\"skills\"]\n",
    "    if \"summary\" in edits1:\n",
    "        summary = edits1[\"summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625975dd-f394-448a-af9a-979d4a95201b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 - Rephrase projects\n",
    "my_resume.experiences = experiences\n",
    "\n",
    "projects = my_resume.rewrite_section(section=my_resume.projects_raw, verbose=False)\n",
    "utils.write_yaml(dict(projects=projects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678981e6-44f3-4217-b3c6-de3b7916c016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the generated output in previous cell.\n",
    "# If any updates are needed, copy the cell output below between the triple quotes\n",
    "# Set value to \"\"\"\" \"\"\"\" if no edits are needed\n",
    "edits = \"\"\"projects:\n",
    "- Published an open source project using prompt engineering with large\n",
    "  language models (LLMs) to\n",
    "  improve resume personalization while ensuring transparency and\n",
    "  trustworthiness, and showcasing expertise in latest generative AI research and implementation.\n",
    "- Prototyped an open source project utilizing self hosted transformer bi-modal embeddings models\n",
    "  for image search, while working with unpublished APIs and ensuring data\n",
    "  privacy, showcasing proficiency in software engineering and building high-quality technical solutions.\n",
    "- Applied advanced geospatial statistical techniques to leverage large-scale LiDAR data for\n",
    "  calculating city-scale building heights, demonstrating the ability to develop scalable solutions\n",
    "  for high-impact applications.\n",
    "\"\"\"\n",
    "\n",
    "edits = edits.strip()\n",
    "if edits:\n",
    "    edits2 = utils.read_yaml(edits)\n",
    "    if \"experiences\" in edits2:\n",
    "        experiences = edits2[\"experiences\"]\n",
    "    if \"projects\" in edits2:\n",
    "        projects = edits2[\"projects\"]\n",
    "    if \"skills\" in edits2:\n",
    "        skills = edits2[\"skills\"]\n",
    "    if \"summary\" in edits2:\n",
    "        summary = edits2[\"summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8ffc17-0e00-44fb-8497-27c79e7e4581",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 5 - Extract skills\n",
    "# This will match the required skills from the job post with your resume sections\n",
    "# Outputs a combined list of skills extracted from the job post and included in the raw resume\n",
    "my_resume.experiences = experiences\n",
    "my_resume.projects = projects\n",
    "\n",
    "skills = my_resume.extract_matched_skills(verbose=False)\n",
    "utils.write_yaml(dict(skills=skills))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0465055f-7203-40d8-89a2-e06b1d01bb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the generated output in previous cell.\n",
    "# If any updates are needed, copy the cell output below between the triple quotes\n",
    "# Set value to \"\"\"\" \"\"\"\" if no edits are needed\n",
    "edits = \"\"\"skills:\n",
    "- category: Technical\n",
    "  skills:\n",
    "  - Python\n",
    "  - Pandas\n",
    "  - Numpy\n",
    "  - Sklearn\n",
    "  - PyTorch\n",
    "  - AWS Sagemaker\n",
    "  - MLOps\n",
    "  - Docker\n",
    "  - Langchain\n",
    "  - Sentence-transformers\n",
    "  - Statistical modeling\n",
    "  - Matplotlib\n",
    "  - Pyspark\n",
    "  - SQL\n",
    "- category: Non-technical\n",
    "  skills:\n",
    "  - Communication\n",
    "  - Proactiveness\n",
    "  - Creativity\n",
    "  - Prioritization\n",
    "  - Leadership\n",
    "  - Agile software development\n",
    "  - Problem solving\n",
    "\"\"\"\n",
    "\n",
    "edits = edits.strip()\n",
    "if edits:\n",
    "    edits3 = utils.read_yaml(edits)\n",
    "    if \"experiences\" in edits3:\n",
    "        experiences = edits3[\"experiences\"]\n",
    "    if \"projects\" in edits3:\n",
    "        projects = edits3[\"projects\"]\n",
    "    if \"skills\" in edits3:\n",
    "        skills = edits3[\"skills\"]\n",
    "    if \"summary\" in edits3:\n",
    "        summary = edits3[\"summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cec373a-2ce3-41da-baf5-ea5efbaf0682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6 - Create a resume summary\n",
    "my_resume.experiences = experiences\n",
    "my_resume.skills = skills\n",
    "my_resume.projects = projects\n",
    "\n",
    "summary = my_resume.write_summary(\n",
    "    verbose=True,\n",
    ")\n",
    "utils.write_yaml(dict(summary=summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b697181-d9fd-4e2b-9721-ffe0a6f19685",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Review the generated output in previous cell.\n",
    "# If any updates are needed, copy the cell output below between the triple quotes\n",
    "# Set value to \"\"\"\" \"\"\"\" if no edits are needed.\n",
    "edits = \"\"\"summary: Results-driven ML and AI researcher with a Ph.D. minor in Artificial Intelligence.\n",
    "  Demonstrated expertise in end-to-end machine\n",
    "  learning development, including data processing, feature engineering, model training,\n",
    "  and evaluation.\n",
    "  Proven track record in leading ML projects in risk forecasting and fraud detection, \n",
    "  and working with large datasets while ensuring data privacy and security compliance.\n",
    "  Published\n",
    "  open source projects utilizing large language models (LLMs) and multimodal embeddings,\n",
    "  ensuring transparency, trustworthiness, and data privacy.\n",
    "  Proficient in Python, SQL, and AWS Sagemaker, and Pyspark. Strong communication and leadership skills with a demonstrated\n",
    "  ability to communicate complex technical ideas with clarity and precision. \n",
    "\"\"\"\n",
    "\n",
    "edits = edits.strip()\n",
    "if edits:\n",
    "    edits4 = utils.read_yaml(edits)\n",
    "    if \"experiences\" in edits4:\n",
    "        experiences = edits4[\"experiences\"]\n",
    "    if \"projects\" in edits4:\n",
    "        projects = edits4[\"projects\"]\n",
    "    if \"skills\" in edits4:\n",
    "        skills = edits4[\"skills\"]\n",
    "    if \"summary\" in edits4:\n",
    "        summary = edits4[\"summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5e6f52-abb8-4026-91df-a60084b5377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7 - Generate final resume yaml for review\n",
    "my_resume.summary = summary\n",
    "my_resume.experiences = experiences\n",
    "my_resume.projects = projects\n",
    "my_resume.skills = skills\n",
    "\n",
    "today_date = datetime.today().strftime(\"%Y%m%d\")\n",
    "resume_filename = os.path.join(\n",
    "    my_files_dir, sanitize_filename(f\"{today_date}__{company_name}__{job_title}\")\n",
    ")\n",
    "resume_final = my_resume.finalize()\n",
    "print(f\"#filename: {resume_filename}.yaml\\n\")\n",
    "utils.write_yaml(resume_final, filename=f\"{resume_filename}.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c974b6-0f3b-4aa5-bbf5-588e22859e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8 - Identify resume improvements\n",
    "# A previously generated resume can also be used here by manually providing resume_filename. Requires the associated parsed job file.\n",
    "final_resume = Resume_Builder(\n",
    "    resume=utils.read_yaml(filename=f\"{resume_filename}.yaml\"),\n",
    "    parsed_job=utils.read_yaml(filename=f\"{resume_filename}.job\"),\n",
    "    is_final=True,\n",
    "    llm_kwargs=llm_kwargs,\n",
    ")\n",
    "improvements = final_resume.suggest_improvements(verbose=False)\n",
    "utils.write_yaml(dict(improvements=improvements))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "33dad12e-a7a1-4384-aabb-f6deea41e229",
   "metadata": {},
   "source": [
    "# Update the yaml file directly as needed based on suggested improvements.\n",
    "# You can re-run the previous and the next cells as many times after editing the yaml file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc802f8e-9d13-45ca-b4f9-01f614cbb591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[my_applications/20231201__Abhineet_Gupta.pdf](<my_applications/20231201__Abhineet_Gupta.pdf>)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 9 - Generate pdf from yaml\n",
    "# Most common errors during pdf generation occur due to special characters. Escape them with backslashes in the yaml, e.g. $ -> \\$\n",
    "resume_filename = os.path.join(\n",
    "    my_files_dir, \"20231201__Abhineet_Gupta\"\n",
    ")\n",
    "pdf_file = utils.generate_pdf(yaml_file=f\"{resume_filename}.yaml\")\n",
    "display(Markdown((f\"[{pdf_file}](<{pdf_file}>)\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785e7827-c5d4-4940-9107-163cea955a16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
